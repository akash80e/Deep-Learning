{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch-Basics.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "S9ecFPogiSrw",
        "WGEfdTGCiSr0",
        "khVJIk4XiSso",
        "uIl-4WSqiSs0",
        "0GYC6c3GiStI",
        "Jgn2cfekiStL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akash80e/Deep-Learning/blob/master/Pytorch_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ejX1jQDdiSrA"
      },
      "source": [
        "## <center> CSCI 6516 : PyTorch Basics</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QPzA0K3biSrB"
      },
      "source": [
        "This is a tutorial on fundamental ideas of PyTorch. This notes is just a starting point. You are encouraged to find out more. The ideal use of this notebook would be as a reference which you keep updating as you learn new things. \n",
        "\n",
        "<b>Credits:</b> Content presented in this tutorial is what I have learnt from my teachers, friends and the python community on stackoverflow. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MiKdIznZiSrD"
      },
      "source": [
        "- PyTorch vs Numpy\n",
        "- Compute Graph\n",
        "  * Directed Acyclic Graph\n",
        "  * Nodes having no parent nodes - Leaf Nodes in PyTorch [Inputs, Parameters, Expected Outputs]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "di5bFJKciSrF",
        "outputId": "b3a51eba-2e33-4028-a114-208faa10d0cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "print(torch.__version__)\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OijIFjZqiSrN"
      },
      "source": [
        "## Tensor - basic unit of representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eDPNIiaeiSrN"
      },
      "source": [
        "* Tensor:\n",
        "    * [Formal] An nth-rank tensor in  m-dimensional space is a mathematical object that has n indices and m^n components and obeys certain transformation rules.\n",
        "    * [Informal] An n-dimensional matrix. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VSdTdxT5iSrQ",
        "colab": {}
      },
      "source": [
        "torch.FloatTensor(np.random.randn(10,5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZwWFTf2tiSrU"
      },
      "source": [
        "### Transpose, View (Reshape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5t6Nt3-BiSrU",
        "colab": {}
      },
      "source": [
        "x = torch.LongTensor(\n",
        "    [\n",
        "       [\n",
        "           [1,2],\n",
        "           [3,4]\n",
        "       ],\n",
        "\n",
        "       [\n",
        "           [5,6],\n",
        "           [7,8]\n",
        "       ],\n",
        "\n",
        "       [\n",
        "           [9,10],\n",
        "           [11,12]\n",
        "       ]\n",
        "    ])\n",
        "x_2d = torch.LongTensor([[1,2],[3,4]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P4sgaj64iSrW",
        "colab": {}
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gZCBFgQ_iSre"
      },
      "source": [
        "<b> Transpose </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW01Fu4iklq1",
        "colab_type": "text"
      },
      "source": [
        ".t , .transpose and .permute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RFkk9mbmiSrf",
        "colab": {}
      },
      "source": [
        "x.transpose(dim0=1,dim1=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C8wuWbotiSrh",
        "colab": {}
      },
      "source": [
        "x.permute(0,1,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mX2WRerOiSrk"
      },
      "source": [
        "<b> Reshape/View </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YPQCVxCCiSrk",
        "colab": {}
      },
      "source": [
        "x.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gTujOUmbiSro",
        "colab": {}
      },
      "source": [
        "x.reshape(1,-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3sWpv4TklrD",
        "colab_type": "text"
      },
      "source": [
        "<b> Internals of Transpose </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73djCzLSklrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To Do"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S9ecFPogiSrw"
      },
      "source": [
        "#### Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "amk708m9iSrw"
      },
      "source": [
        "Reshape x into a 2D matrix such that column 1 has [1,2,3,4]; column 2 has [5,6,7,8] and column 3 has [9,10,11,12]. \n",
        "\n",
        "Challenge: Can you give another way of achieving the same? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijgOZgjUklrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DFeh8koviSrx",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WGEfdTGCiSr0"
      },
      "source": [
        "## Arithmetic operations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xXzysdhoiSr0"
      },
      "source": [
        "<b> Addition/Subtraction </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qqyO0VrxiSr1",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "90OD_SENiSr3",
        "colab": {}
      },
      "source": [
        "x + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QTyW6eBViSr6",
        "colab": {}
      },
      "source": [
        "x + x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k1Tz0umiiSr9"
      },
      "source": [
        "<b> Multiplication </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "paXk25c7iSr9",
        "colab": {}
      },
      "source": [
        "x_2d * 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GnuWV5ZNiSsC",
        "colab": {}
      },
      "source": [
        "x_2d * x_2d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "96auq6yRiSsE",
        "colab": {}
      },
      "source": [
        "torch.matmul(x_2d,x_2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tp3JHXoiiSsG"
      },
      "source": [
        "<b> Division </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qdkPAdmoiSsI",
        "colab": {}
      },
      "source": [
        "x_2d/3.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zOPYcM4UiSsL",
        "colab": {}
      },
      "source": [
        "x_2d/x_2d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Oy_VIOhciSsO"
      },
      "source": [
        "<b> Broadcasting </b> <br>\n",
        "Broadcasting is \"auto-correction\" of one of the arguments in order to bring them to the correct dimensions. \n",
        "* Replicates the 1/more dimensions of one or both the tensors to match them.\n",
        "* From Scipy:\n",
        "<pre>\n",
        "When operating on two arrays, NumPy compares their shapes element-wise. It starts with \n",
        "the trailing dimensions, and works its way forward. Two dimensions are compatible when:\n",
        "    * they are equal, or\n",
        "    * one of them is 1\n",
        "</pre>\n",
        "* Makes a best effort to auto-correct; throws error if it cannot. \n",
        "* Not applicable to all operators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qoI_DMziiSsP",
        "colab": {}
      },
      "source": [
        "x_2d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a5TA2WW1iSsU",
        "colab": {}
      },
      "source": [
        "y = np.array([[1,2]])\n",
        "print(y.shape)\n",
        "x_2d + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nf3JFR5DiSsX",
        "colab": {}
      },
      "source": [
        "y = np.array([[1],[2]])\n",
        "print(y.shape)\n",
        "x_2d + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bG9oDK_HiSsZ",
        "colab": {}
      },
      "source": [
        "y = np.array([[1,2]])\n",
        "print(y.shape)\n",
        "x * y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8amS--kWiSse",
        "colab": {}
      },
      "source": [
        "y = np.array([[1],[2]])\n",
        "print(y.shape)\n",
        "x_2d * y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UjRVjJJOiSsg",
        "colab": {}
      },
      "source": [
        "y = np.array([[1,2]])\n",
        "print(y.shape)\n",
        "x_2d / y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ydMTdHaIiSsi",
        "colab": {}
      },
      "source": [
        "y = np.array([[1],[2]])\n",
        "print(y.shape)\n",
        "x_2d / y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6bdqFpLViSsl"
      },
      "source": [
        "<b>Perils of broadcasting</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dQn9eEmSiSsl",
        "colab": {}
      },
      "source": [
        "p = torch.FloatTensor([[1],[2],[3]])\n",
        "q = torch.FloatTensor([[4,5,6]])\n",
        "print(p.shape,q.shape)\n",
        "p+q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "khVJIk4XiSso"
      },
      "source": [
        "## Idea of dim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8bOFToI7iSsp",
        "colab": {}
      },
      "source": [
        "x_2d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6SIO4RS9iSsu",
        "colab": {}
      },
      "source": [
        "F.softmax(x_2d.float(),dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hdLIvMKwiSsx",
        "colab": {}
      },
      "source": [
        "F.softmax(x_2d.float(),dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uIl-4WSqiSs0"
      },
      "source": [
        "## Unary Tensor functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EtPz2MhklsH",
        "colab_type": "text"
      },
      "source": [
        "sum, mean, max, min, etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d9VdKxeklsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_2d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ijw0QPyPiSs0",
        "colab": {}
      },
      "source": [
        "x_2d.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jozaHYPDiSs2",
        "colab": {}
      },
      "source": [
        "x_2d.sum(dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "35ucLMG-iSs8",
        "colab": {}
      },
      "source": [
        "x_2d.sum(dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ysnG16M4iStA",
        "colab": {}
      },
      "source": [
        "x_2d.sum(dim=1,keepdims=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vmPPse_5iStE"
      },
      "source": [
        "<b> Exercise </b> <br>\n",
        "Find the sum of each of the 2x2 matrices of x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w-pq-T4PiStE",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGNyfZjrklsa",
        "colab_type": "text"
      },
      "source": [
        "Other important/useful functions:\n",
        "- torch.log\n",
        "- torch.abs\n",
        "- torch.exp\n",
        "- torch.cat\n",
        "- torch.stack\n",
        "- torch.where\n",
        "- F.leaky_relu, F.sigmoid, F.tanh, F.conv*, etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47dHH5hpklsb",
        "colab_type": "text"
      },
      "source": [
        "## Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj81boeDklsb",
        "colab_type": "text"
      },
      "source": [
        "Derivatives: retain_graph, create_graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv-Yr0VFklsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.FloatTensor([1]).requires_grad_(True)\n",
        "y = torch.FloatTensor([2]).requires_grad_(True)\n",
        "f = x**2 + y**2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHd8WsSgklse",
        "colab_type": "text"
      },
      "source": [
        "Leaf Tensors and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QghzjdWBklsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = torch.tensor([[1.0]],requires_grad=True)\n",
        "optim = torch.optim.SGD([w],lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R69ZOG8Wklsi",
        "colab_type": "text"
      },
      "source": [
        "Logistic Regression Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWcBGeJOklsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from sklearn.datasets import make_blobs\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import xlim\n",
        "\n",
        "# Create linearly separable data\n",
        "x,y = make_blobs(n_samples=1000, n_features=2, centers=[[-4,-2],[4,2]], cluster_std=1, shuffle=True)\n",
        "colors = np.array(['red','green'])\n",
        "plt.scatter(x[:, 0], x[:, 1],\n",
        "            color = colors[y].tolist(), marker='.')\n",
        "xmin, xmax = xlim()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uczUtecQklsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self,input_dimensions):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        \n",
        "        # Define trainable parameters\n",
        "        self.w = torch.nn.Parameter(torch.randn(input_dimensions,1))\n",
        "        self.b = torch.nn.Parameter(torch.zeros(1))\n",
        "        \n",
        "    def train(self,X,Y):\n",
        "        \"\"\"\n",
        "        X: an array of shape [*, input_dimensions]\n",
        "        Y: an array of shape [*,1]\n",
        "        \"\"\"\n",
        "        X = torch.FloatTensor(X).view(-1,self.w.shape[0])\n",
        "        Y = torch.FloatTensor(Y).view(-1,1)\n",
        "        \n",
        "        print(\"Training...\")\n",
        "\n",
        "        optim = torch.optim.SGD([self.w,self.b],lr=0.1)\n",
        "        \n",
        "        for i in range(50):\n",
        "            pred = X@self.w + self.b\n",
        "            pred = F.sigmoid(pred)\n",
        "            \n",
        "            cost = None # Cross-entropy loss\n",
        "            reg = None  # L2 regularization \n",
        "\n",
        "            optim.zero_grad()\n",
        "            cost.backward()\n",
        "            reg.backward()\n",
        "            optim.step()\n",
        "            \n",
        "        print(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5MN8xU1klsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lg = LogisticRegression(input_dimensions=2)\n",
        "lg.train(x,y)\n",
        "w,b = lg.w, lg.b\n",
        "\n",
        "plt.scatter(x[:, 0], x[:, 1],\n",
        "            color = colors[y].tolist(), marker='.')\n",
        "xmin, xmax = xlim()\n",
        "\n",
        "ymin = -(b+w[0][0]*xmin)/w[1][0]\n",
        "ymax = -(b+w[0][0]*xmax)/w[1][0]\n",
        "\n",
        "plt.plot([xmin,xmax],[ymin,ymax], color=\"black\", linestyle='-', linewidth=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HCPFaYLklsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}